{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import os\n",
    "import clickhouse_connect\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "CH_USER = os.getenv('CH_USER')\n",
    "CH_PASS = os.getenv('CH_PASS')\n",
    "CH_IP = os.getenv('CH_IP')\n",
    "\n",
    "root_path = \".\"\n",
    "\n",
    "client = clickhouse_connect.get_client(host=CH_IP, port=8123, username=CH_USER, password=CH_PASS)\n",
    "\n",
    "your_mlflow_tracking_uri = f'{root_path}/mlruns' # for docker mlflow server\n",
    "# your_mlflow_tracking_uri = \"http://127.0.0.1:5000\" # for local mlflow server\n",
    "# your_mlflow_tracking_uri = MLFLOW_TRACKING_URI # for remote mlflow server\n",
    "mlflow.set_tracking_uri(your_mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12 added as a dependency\n",
      "com.clickhouse#clickhouse-jdbc added as a dependency\n",
      "com.clickhouse#clickhouse-http-client added as a dependency\n",
      "org.apache.httpcomponents.client5#httpclient5 added as a dependency\n",
      "ai.catboost#catboost-spark_3.5_2.12 added as a dependency\n",
      "com.microsoft.azure#synapseml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7f9b1db0-fbc5-4f15-9a11-60c62ac96008;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12;0.8.0 in central\n",
      "\tfound com.clickhouse#clickhouse-jdbc;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-client;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-data;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-http-client;0.7.1-patch1 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.2.1 in central\n",
      "\tfound org.apache.httpcomponents.client5#httpclient5;5.3.1 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.2.4 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.2.4 in central\n",
      "\tfound ai.catboost#catboost-spark_3.5_2.12;1.2.7 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.6.0 in central\n",
      "\tfound com.google.guava#guava;32.0.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.33.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;2.8 in central\n",
      "\tfound commons-io#commons-io;2.7 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.11 in central\n",
      "\tfound org.apache.commons#commons-text;1.10.0 in central\n",
      "\tfound org.json4s#json4s-jackson_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-core_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-ast_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-scalap_2.12;3.7.0-M11 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 in central\n",
      "\tfound io.github.classgraph#classgraph;4.8.98 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.1 in central\n",
      "\tfound ai.catboost#catboost-common;1.2.7 in central\n",
      "\tfound javax.validation#validation-api;1.1.0.Final in central\n",
      "\tfound ai.catboost#catboost-spark-macros_2.12;1.2.7 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.12 in central\n",
      "\tfound com.microsoft.azure#synapseml_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.azure#synapseml-core_2.12;1.0.8 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.4.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound org.scalactic#scalactic_2.12;3.2.14 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.15 in central\n",
      "\tfound io.spray#spray-json_2.12;1.3.5 in central\n",
      "\tfound com.jcraft#jsch;0.1.54 in central\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.linkedin.isolation-forest#isolation-forest_3.4.2_2.12;3.0.4 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.10 in central\n",
      "\tfound org.testng#testng;6.8.8 in central\n",
      "\tfound org.beanshell#bsh;2.0b4 in central\n",
      "\tfound com.beust#jcommander;1.27 in central\n",
      "\tfound org.scalanlp#breeze_2.12;2.1.0 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;2.1.0 in central\n",
      "\tfound org.typelevel#spire_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-macros_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#algebra_2.12;2.0.1 in central\n",
      "\tfound org.typelevel#cats-kernel_2.12;2.1.1 in central\n",
      "\tfound org.typelevel#spire-platform_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-util_2.12;0.17.0 in central\n",
      "\tfound dev.ludovic.netlib#blas;3.0.1 in central\n",
      "\tfound net.sourceforge.f2j#arpack_combined_all;0.1 in central\n",
      "\tfound dev.ludovic.netlib#lapack;3.0.1 in central\n",
      "\tfound dev.ludovic.netlib#arpack;3.0.1 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.wendykierp#JTransforms;3.1 in central\n",
      "\tfound pl.edu.icm#JLargeArrays;1.5 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.7.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-deep-learning_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.azure#synapseml-opencv_2.12;1.0.8 in central\n",
      "\tfound org.openpnp#opencv;3.2.0-1 in central\n",
      "\tfound com.microsoft.azure#onnx-protobuf_2.12;0.9.3 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-cognitive_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.cognitiveservices.speech#client-sdk;1.24.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-vw_2.12;1.0.8 in central\n",
      "\tfound com.github.vowpalwabbit#vw-jni;9.3.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-lightgbm_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.ml.lightgbm#lightgbmlib;3.3.510 in central\n",
      ":: resolution report :: resolve 1706ms :: artifacts dl 43ms\n",
      "\t:: modules in use:\n",
      "\tai.catboost#catboost-common;1.2.7 from central in [default]\n",
      "\tai.catboost#catboost-spark-macros_2.12;1.2.7 from central in [default]\n",
      "\tai.catboost#catboost-spark_3.5_2.12;1.2.7 from central in [default]\n",
      "\tcom.beust#jcommander;1.27 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.10 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-client;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-data;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-http-client;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-jdbc;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12;0.8.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 from central in [default]\n",
      "\tcom.github.vowpalwabbit#vw-jni;9.3.0 from central in [default]\n",
      "\tcom.github.wendykierp#JTransforms;3.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;32.0.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;2.8 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.54 from central in [default]\n",
      "\tcom.linkedin.isolation-forest#isolation-forest_3.4.2_2.12;3.0.4 from central in [default]\n",
      "\tcom.microsoft.azure#onnx-protobuf_2.12;0.9.3 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-cognitive_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-core_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-deep-learning_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-lightgbm_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-opencv_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-vw_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.cognitiveservices.speech#client-sdk;1.24.1 from central in [default]\n",
      "\tcom.microsoft.ml.lightgbm#lightgbmlib;3.3.510 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-io#commons-io;2.7 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdev.ludovic.netlib#arpack;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#blas;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#lapack;3.0.1 from central in [default]\n",
      "\tio.github.classgraph#classgraph;4.8.98 from central in [default]\n",
      "\tio.spray#spray-json_2.12;1.3.5 from central in [default]\n",
      "\tjavax.validation#validation-api;1.1.0.Final from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\tnet.sourceforge.f2j#arpack_combined_all;0.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.11 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.10.0 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.2.4 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.2.4 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.4.1 from central in [default]\n",
      "\torg.beanshell#bsh;2.0b4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.33.0 from central in [default]\n",
      "\torg.json4s#json4s-ast_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-core_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-jackson_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-scalap_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.openpnp#opencv;3.2.0-1 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.15 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.7.0 from central in [default]\n",
      "\torg.scalactic#scalactic_2.12;3.2.14 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;2.1.0 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;2.1.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.testng#testng;6.8.8 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.typelevel#algebra_2.12;2.0.1 from central in [default]\n",
      "\torg.typelevel#cats-kernel_2.12;2.1.1 from central in [default]\n",
      "\torg.typelevel#spire-macros_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-platform_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-util_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire_2.12;0.17.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 from central in [default]\n",
      "\tpl.edu.icm#JLargeArrays;1.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.2.1 by [org.apache.httpcomponents.client5#httpclient5;5.3.1] in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.2 by [org.apache.httpcomponents.core5#httpcore5-h2;5.2.4] in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.2.1 by [org.apache.httpcomponents.core5#httpcore5;5.2.4] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.6.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.12.0 by [org.apache.commons#commons-lang3;3.11] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.2 by [com.fasterxml.jackson.core#jackson-databind;2.15.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.12 by [org.scala-lang#scala-reflect;2.12.15] in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.1.3 by [org.apache.httpcomponents.client5#httpclient5;5.3.1] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.2.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-math3;3.5 by [org.apache.commons#commons-math3;3.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   94  |   0   |   0   |   13  ||   81  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7f9b1db0-fbc5-4f15-9a11-60c62ac96008\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 81 already retrieved (0kB/30ms)\n",
      "25/01/01 14:47:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/01 14:47:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "\n",
    "# ml\n",
    "from pyspark.ml import Pipeline as spk_pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder as spk_OneHotEncoder, StandardScaler as spk_StandardScaler, VectorAssembler as spk_VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler as spk_MinMaxScaler, StringIndexer as spk_StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator as spk_RegressionEvaluator\n",
    "\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "#https://repo1.maven.org/maven2/com/github/housepower/clickhouse-native-jdbc/2.7.1/clickhouse-native-jdbc-2.7.1.jar\n",
    "# spark connector https://github.com/ClickHouse/spark-clickhouse-connector\n",
    "# https://mvnrepository.com/artifact/com.clickhouse\n",
    "# https://github.com/housepower/ClickHouse-Native-JDBC, For Spark 3.2 and upper, Spark ClickHouse Connector (see upper) is recommended.\n",
    "# https://clickhouse.com/docs/en/integrations/apache-spark/spark-native-connector\n",
    "packages = [\n",
    "    \"com.clickhouse.spark:clickhouse-spark-runtime-3.5_2.12:0.8.0\"\n",
    "    # \"com.github.housepower:clickhouse-spark-runtime-3.4_2.12:0.7.3\"\n",
    "    ,\"com.clickhouse:clickhouse-jdbc:0.7.1-patch1\"\n",
    "    # ,\"com.clickhouse:clickhouse-jdbc:0.6.0-patch5\"\n",
    "    ,\"com.clickhouse:clickhouse-http-client:0.7.1-patch1\"\n",
    "    # ,\"com.clickhouse:clickhouse-http-client:0.6.0-patch5\"\n",
    "    ,\"org.apache.httpcomponents.client5:httpclient5:5.3.1\"\n",
    "    # for jdbc 2.7.1 required java 8/11\n",
    "    # ,\"com.github.housepower:clickhouse-native-jdbc:2.7.1\"\n",
    "    ,\"ai.catboost:catboost-spark_3.5_2.12:1.2.7\"\n",
    "    ,\"com.microsoft.azure:synapseml_2.12:1.0.8\"\n",
    "\n",
    "]\n",
    "\n",
    "exclude_packages = [\n",
    "    \"org.scala-lang:scala-reflect\"\n",
    "    ,\"org.apache.spark:spark-tags_2.12\"\n",
    "    ,\"org.scalactic:scalactic_2.12\"\n",
    "    ,\"org.scalatest:scalatest_2.12\"\n",
    "    ,\"com.fasterxml.jackson.core:jackson-databind\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ram = 60\n",
    "cpu = 22*3\n",
    "# Define the application name and setup session\n",
    "appName = \"Connect To ClickHouse via PySpark\"\n",
    "spark = (SparkSession.builder\n",
    "         .appName(appName)\n",
    "         .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "         .config(\"spark.sql.catalog.clickhouse\", \"com.clickhouse.spark.ClickHouseCatalog\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.host\", CH_IP)\n",
    "         .config(\"spark.sql.catalog.clickhouse.protocol\", \"http\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.http_port\", \"8123\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.user\", CH_USER)\n",
    "         .config(\"spark.sql.catalog.clickhouse.password\", CH_PASS)\n",
    "         .config(\"spark.sql.catalog.clickhouse.database\", \"default\")\n",
    "        #  .config(\"spark.spark.clickhouse.write.compression.codec\", \"lz4\")\n",
    "        #  .config(\"spark.clickhouse.read.compression.codec\", \"lz4\")\n",
    "        #  .config(\"spark.clickhouse.write.format\", \"arrow\")\n",
    "         #    .config(\"spark.clickhouse.write.distributed.convertLocal\", \"true\") l\n",
    "         #    .config(\"spark.clickhouse.write.repartitionNum\", \"1\") \n",
    "         #.config(\"spark.clickhouse.write.maxRetry\", \"1000\")\n",
    "         #    .config(\"spark.clickhouse.write.repartitionStrictly\", \"true\") \n",
    "         #    .config(\"spark.clickhouse.write.distributed.useClusterNodes\", \"false\") \n",
    "        #  .config(\"spark.clickhouse.write.batchSize\", \"1000000\")\n",
    "         #.config(\"spark.sql.catalog.clickhouse.socket_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.sql.catalog.clickhouse.connection_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.sql.catalog.clickhouse.query_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.socket_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.connection_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.query_timeout\", \"600000000\")         \n",
    "         .config(\"spark.executor.memory\", f\"{ram}g\")\n",
    "        #  .config(\"spark.executor.cores\", \"5\")\n",
    "         .config(\"spark.driver.maxResultSize\", f\"{ram}g\")\n",
    "         .config(\"spark.driver.memory\", f\"{ram}g\")\n",
    "         .config(\"spark.executor.memoryOverhead\", f\"{ram}g\")\n",
    "        #  .config(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "         .getOrCreate()\n",
    "         )\n",
    "\n",
    "# LightGBM set config https://microsoft.github.io/SynapseML/docs/Get%20Started/Install%20SynapseML/\n",
    "# spark.conf.set(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "# spark.conf.set(\"spark.jars.excludes\", \",\".join(exclude_packages))\n",
    "# spark.conf.set(\"spark.yarn.user.classpath.first\", \"true\")\n",
    "# spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "\n",
    "#SedonaRegistrator.registerAll(spark)\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse\", \"xenon.clickhouse.ClickHouseCatalog\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.host\", \"127.0.0.1\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.protocol\", \"http\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.http_port\", \"8123\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.user\", \"default\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.password\", \"\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.database\", \"default\")\n",
    "\n",
    "\n",
    "\n",
    "from catboost_spark import CatBoostRegressor as CatBoostRegressor_spark\n",
    "from synapse.ml.lightgbm import LightGBMRegressor as LightGBMRegressor_spark\n",
    "\n",
    "\n",
    "spark.sql(\"use clickhouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-Side: FastAPI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "class DataFrameInput(BaseModel):\n",
    "    data: List[Dict]  # Expecting a list of dictionaries as input\n",
    "\n",
    "@app.post(\"/process-dataframe\")\n",
    "async def process_dataframe(input_data: DataFrameInput):\n",
    "    # Convert the JSON data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(input_data.data)\n",
    "    \n",
    "    # Modify the DataFrame (example: add a new column)\n",
    "    df[\"new_column\"] = df[\"column1\"] * 2  # Assuming 'column1' exists in the input\n",
    "    \n",
    "    # Convert the modified DataFrame back to JSON\n",
    "    response_data = df.to_dict(orient=\"records\")\n",
    "    return {\"data\": response_data}\n",
    "\n",
    "\n",
    "@app.get(\"/control\")\n",
    "async def get_control():\n",
    "    control = client.query('''\n",
    "        SELECT * \n",
    "        FROM ycup.control\n",
    "        LIMIT 10'''\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client-Side: Sending and Receiving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clickhouse connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Execute the query to retrieve the list of tables\n",
    "# tables_query = client.query('SHOW TABLES IN ycup')\n",
    "\n",
    "# # Fetch the data from the result\n",
    "# tables = tables_query.result_rows\n",
    "\n",
    "# tables[0][0]\n",
    "\n",
    "# # Execute the query\n",
    "# query = f'SELECT * FROM ycup.{tables[0][0]} LIMIT 10'\n",
    "# result = client.query(query)\n",
    "\n",
    "# # Fetch the data and column names\n",
    "# data = result.result_rows  # Retrieves the rows of the result\n",
    "# columns = result.column_names  # Retrieves the column names\n",
    "\n",
    "# pd.DataFrame(data, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'ycup'\n",
    "# list of tables in db\n",
    "tables = spark.sql(f'SHOW TABLES in {db}').collect()\n",
    "\n",
    "df_list = {}\n",
    "for table in tables:\n",
    "    table_name = table.tableName\n",
    "    df = spark.sql(f'SELECT * FROM {db}.{table_name} limit 10').toPandas()\n",
    "    df_list[table_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stamp_ns</th>\n",
       "      <th>acceleration_level</th>\n",
       "      <th>steering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36479492</td>\n",
       "      <td>-929</td>\n",
       "      <td>5.739836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76459951</td>\n",
       "      <td>-926</td>\n",
       "      <td>5.280618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>116678417</td>\n",
       "      <td>-918</td>\n",
       "      <td>5.039505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>156788958</td>\n",
       "      <td>-908</td>\n",
       "      <td>4.734873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>196857808</td>\n",
       "      <td>-897</td>\n",
       "      <td>4.387096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>236974997</td>\n",
       "      <td>-892</td>\n",
       "      <td>4.014573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>276890721</td>\n",
       "      <td>-892</td>\n",
       "      <td>3.627408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>316915752</td>\n",
       "      <td>-901</td>\n",
       "      <td>3.191926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>356884436</td>\n",
       "      <td>-911</td>\n",
       "      <td>2.748362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>396895329</td>\n",
       "      <td>-918</td>\n",
       "      <td>2.286391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   stamp_ns  acceleration_level  steering\n",
       "0   0   36479492                -929  5.739836\n",
       "1   0   76459951                -926  5.280618\n",
       "2   0  116678417                -918  5.039505\n",
       "3   0  156788958                -908  4.734873\n",
       "4   0  196857808                -897  4.387096\n",
       "5   0  236974997                -892  4.014573\n",
       "6   0  276890721                -892  3.627408\n",
       "7   0  316915752                -901  3.191926\n",
       "8   0  356884436                -911  2.748362\n",
       "9   0  396895329                -918  2.286391"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '36479492', '-929', '5.7398357\\n0', '76459951', '-926', '5.2806177\\n0', '116678417', '-918', '5.039505\\n0', '156788958', '-908', '4.7348733\\n0', '196857808', '-897', '4.387096\\n0', '236974997', '-892', '4.014573\\n0', '276890721', '-892', '3.6274078\\n0', '316915752', '-901', '3.191926\\n0', '356884436', '-911', '2.7483618\\n0', '396895329', '-918', '2.2863915']\n"
     ]
    }
   ],
   "source": [
    "# get data from clickhouse\n",
    "print(client.command('select * from ycup.control limit 10'))\n",
    "\n",
    "\n",
    "# control = client.query('''\n",
    "#         SELECT * \n",
    "#         FROM ycup.control\n",
    "#         LIMIT 10                        \n",
    "# ''')\n",
    "\n",
    "\n",
    "# pd.DataFrame(control, columns=['id', 'stamp_ns', 'acceleration_level', 'steering'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame to send\n",
    "control = pd.DataFrame(\n",
    "    client.command('''\n",
    "        SELECT * \n",
    "        FROM ycup.control                   \n",
    "    ''')\n",
    ")\n",
    "\n",
    "localization = client.command('''\n",
    "    SELECT * \n",
    "    FROM ycup.localization                   \n",
    "''')\n",
    "\n",
    "metadata = client.command('''\n",
    "    SELECT * \n",
    "    FROM ycup.metadata                   \n",
    "''')\n",
    "\n",
    "# Convert DataFrame to JSON format\n",
    "data_to_send = {\"data\": df.to_dict(orient=\"records\")}\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(\"http://127.0.0.1:8000/process-dataframe\", json=data_to_send)\n",
    "\n",
    "# Convert the response JSON back into a DataFrame\n",
    "if response.status_code == 200:\n",
    "    returned_data = response.json()[\"data\"]\n",
    "    result_df = pd.DataFrame(returned_data)\n",
    "    print(result_df)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running the Server\n",
    "\n",
    "\n",
    "```\n",
    "uvicorn your_script_name:app --reload\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
