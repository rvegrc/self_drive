{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import os\n",
    "import clickhouse_connect\n",
    "\n",
    "import sklearn\n",
    "\n",
    "sklearn.set_config(transform_output='pandas')\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "CH_USER = os.getenv('CH_USER')\n",
    "CH_PASS = os.getenv('CH_PASS')\n",
    "CH_IP = os.getenv('CH_IP')\n",
    "\n",
    "from api.union_dfs import union_dfs\n",
    "from api.df_preprocessor import df_preprocessor\n",
    "\n",
    "root_path = \"./api\"\n",
    "preprocessor_path = f\"{root_path}/preprocessor\"\n",
    "\n",
    "client = clickhouse_connect.get_client(host=CH_IP, port=8123, username=CH_USER, password=CH_PASS)\n",
    "\n",
    "your_mlflow_tracking_uri = f'{root_path}/mlruns' # for docker mlflow server\n",
    "# your_mlflow_tracking_uri = \"http://127.0.0.1:5000\" # for local mlflow server\n",
    "# your_mlflow_tracking_uri = MLFLOW_TRACKING_URI # for remote mlflow server\n",
    "mlflow.set_tracking_uri(your_mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12 added as a dependency\n",
      "com.clickhouse#clickhouse-jdbc added as a dependency\n",
      "com.clickhouse#clickhouse-http-client added as a dependency\n",
      "org.apache.httpcomponents.client5#httpclient5 added as a dependency\n",
      "ai.catboost#catboost-spark_3.5_2.12 added as a dependency\n",
      "com.microsoft.azure#synapseml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fc57db16-8e73-4932-a58a-c86243948a28;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12;0.8.0 in central\n",
      "\tfound com.clickhouse#clickhouse-jdbc;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-client;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-data;0.7.1-patch1 in central\n",
      "\tfound com.clickhouse#clickhouse-http-client;0.7.1-patch1 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.2.1 in central\n",
      "\tfound org.apache.httpcomponents.client5#httpclient5;5.3.1 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.2.4 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.2.4 in central\n",
      "\tfound ai.catboost#catboost-spark_3.5_2.12;1.2.7 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.6.0 in central\n",
      "\tfound com.google.guava#guava;32.0.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.33.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;2.8 in central\n",
      "\tfound commons-io#commons-io;2.7 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.11 in central\n",
      "\tfound org.apache.commons#commons-text;1.10.0 in central\n",
      "\tfound org.json4s#json4s-jackson_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-core_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-ast_2.12;3.7.0-M11 in central\n",
      "\tfound org.json4s#json4s-scalap_2.12;3.7.0-M11 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 in central\n",
      "\tfound io.github.classgraph#classgraph;4.8.98 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.1 in central\n",
      "\tfound ai.catboost#catboost-common;1.2.7 in central\n",
      "\tfound javax.validation#validation-api;1.1.0.Final in central\n",
      "\tfound ai.catboost#catboost-spark-macros_2.12;1.2.7 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.12 in central\n",
      "\tfound com.microsoft.azure#synapseml_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.azure#synapseml-core_2.12;1.0.8 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.4.1 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound org.scalactic#scalactic_2.12;3.2.14 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.15 in central\n",
      "\tfound io.spray#spray-json_2.12;1.3.5 in central\n",
      "\tfound com.jcraft#jsch;0.1.54 in central\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.linkedin.isolation-forest#isolation-forest_3.4.2_2.12;3.0.4 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.10 in central\n",
      "\tfound org.testng#testng;6.8.8 in central\n",
      "\tfound org.beanshell#bsh;2.0b4 in central\n",
      "\tfound com.beust#jcommander;1.27 in central\n",
      "\tfound org.scalanlp#breeze_2.12;2.1.0 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;2.1.0 in central\n",
      "\tfound org.typelevel#spire_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-macros_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#algebra_2.12;2.0.1 in central\n",
      "\tfound org.typelevel#cats-kernel_2.12;2.1.1 in central\n",
      "\tfound org.typelevel#spire-platform_2.12;0.17.0 in central\n",
      "\tfound org.typelevel#spire-util_2.12;0.17.0 in central\n",
      "\tfound dev.ludovic.netlib#blas;3.0.1 in central\n",
      "\tfound net.sourceforge.f2j#arpack_combined_all;0.1 in central\n",
      "\tfound dev.ludovic.netlib#lapack;3.0.1 in central\n",
      "\tfound dev.ludovic.netlib#arpack;3.0.1 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.wendykierp#JTransforms;3.1 in central\n",
      "\tfound pl.edu.icm#JLargeArrays;1.5 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.7.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-deep-learning_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.azure#synapseml-opencv_2.12;1.0.8 in central\n",
      "\tfound org.openpnp#opencv;3.2.0-1 in central\n",
      "\tfound com.microsoft.azure#onnx-protobuf_2.12;0.9.3 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-cognitive_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.cognitiveservices.speech#client-sdk;1.24.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-vw_2.12;1.0.8 in central\n",
      "\tfound com.github.vowpalwabbit#vw-jni;9.3.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-lightgbm_2.12;1.0.8 in central\n",
      "\tfound com.microsoft.ml.lightgbm#lightgbmlib;3.3.510 in central\n",
      ":: resolution report :: resolve 5007ms :: artifacts dl 141ms\n",
      "\t:: modules in use:\n",
      "\tai.catboost#catboost-common;1.2.7 from central in [default]\n",
      "\tai.catboost#catboost-spark-macros_2.12;1.2.7 from central in [default]\n",
      "\tai.catboost#catboost-spark_3.5_2.12;1.2.7 from central in [default]\n",
      "\tcom.beust#jcommander;1.27 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.10 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-client;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-data;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-http-client;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse#clickhouse-jdbc;0.7.1-patch1 from central in [default]\n",
      "\tcom.clickhouse.spark#clickhouse-spark-runtime-3.5_2.12;0.8.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-scala_2.12;2.15.2 from central in [default]\n",
      "\tcom.github.vowpalwabbit#vw-jni;9.3.0 from central in [default]\n",
      "\tcom.github.wendykierp#JTransforms;3.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;32.0.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;2.8 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.54 from central in [default]\n",
      "\tcom.linkedin.isolation-forest#isolation-forest_3.4.2_2.12;3.0.4 from central in [default]\n",
      "\tcom.microsoft.azure#onnx-protobuf_2.12;0.9.3 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-cognitive_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-core_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-deep-learning_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-lightgbm_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-opencv_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-vw_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml_2.12;1.0.8 from central in [default]\n",
      "\tcom.microsoft.cognitiveservices.speech#client-sdk;1.24.1 from central in [default]\n",
      "\tcom.microsoft.ml.lightgbm#lightgbmlib;3.3.510 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-io#commons-io;2.7 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdev.ludovic.netlib#arpack;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#blas;3.0.1 from central in [default]\n",
      "\tdev.ludovic.netlib#lapack;3.0.1 from central in [default]\n",
      "\tio.github.classgraph#classgraph;4.8.98 from central in [default]\n",
      "\tio.spray#spray-json_2.12;1.3.5 from central in [default]\n",
      "\tjavax.validation#validation-api;1.1.0.Final from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\tnet.sourceforge.f2j#arpack_combined_all;0.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.11 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.10.0 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.2.4 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.2.4 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.4.1 from central in [default]\n",
      "\torg.beanshell#bsh;2.0b4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.33.0 from central in [default]\n",
      "\torg.json4s#json4s-ast_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-core_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-jackson_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.json4s#json4s-scalap_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.openpnp#opencv;3.2.0-1 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.15 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.7.0 from central in [default]\n",
      "\torg.scalactic#scalactic_2.12;3.2.14 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;2.1.0 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;2.1.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.testng#testng;6.8.8 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.typelevel#algebra_2.12;2.0.1 from central in [default]\n",
      "\torg.typelevel#cats-kernel_2.12;2.1.1 from central in [default]\n",
      "\torg.typelevel#spire-macros_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-platform_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire-util_2.12;0.17.0 from central in [default]\n",
      "\torg.typelevel#spire_2.12;0.17.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.1 from central in [default]\n",
      "\tpl.edu.icm#JLargeArrays;1.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.2.1 by [org.apache.httpcomponents.client5#httpclient5;5.3.1] in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.2 by [org.apache.httpcomponents.core5#httpcore5-h2;5.2.4] in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.2.1 by [org.apache.httpcomponents.core5#httpcore5;5.2.4] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.6.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.12.0 by [org.apache.commons#commons-lang3;3.11] in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.2 by [com.fasterxml.jackson.core#jackson-databind;2.15.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.12 by [org.scala-lang#scala-reflect;2.12.15] in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.1.3 by [org.apache.httpcomponents.client5#httpclient5;5.3.1] in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.2.0 by [org.scala-lang.modules#scala-collection-compat_2.12;2.7.0] in [default]\n",
      "\torg.apache.commons#commons-math3;3.5 by [org.apache.commons#commons-math3;3.2] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   94  |   0   |   0   |   13  ||   81  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fc57db16-8e73-4932-a58a-c86243948a28\n",
      "\tconfs: [default]\n",
      "\t72 artifacts copied, 9 already retrieved (316463kB/1887ms)\n",
      "25/01/08 13:27:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/08 13:27:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "\n",
    "# ml\n",
    "from pyspark.ml import Pipeline as spk_pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder as spk_OneHotEncoder, StandardScaler as spk_StandardScaler, VectorAssembler as spk_VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler as spk_MinMaxScaler, StringIndexer as spk_StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator as spk_RegressionEvaluator\n",
    "\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "#https://repo1.maven.org/maven2/com/github/housepower/clickhouse-native-jdbc/2.7.1/clickhouse-native-jdbc-2.7.1.jar\n",
    "# spark connector https://github.com/ClickHouse/spark-clickhouse-connector\n",
    "# https://mvnrepository.com/artifact/com.clickhouse\n",
    "# https://github.com/housepower/ClickHouse-Native-JDBC, For Spark 3.2 and upper, Spark ClickHouse Connector (see upper) is recommended.\n",
    "# https://clickhouse.com/docs/en/integrations/apache-spark/spark-native-connector\n",
    "packages = [\n",
    "    \"com.clickhouse.spark:clickhouse-spark-runtime-3.5_2.12:0.8.0\"\n",
    "    # \"com.github.housepower:clickhouse-spark-runtime-3.4_2.12:0.7.3\"\n",
    "    ,\"com.clickhouse:clickhouse-jdbc:0.7.1-patch1\"\n",
    "    # ,\"com.clickhouse:clickhouse-jdbc:0.6.0-patch5\"\n",
    "    ,\"com.clickhouse:clickhouse-http-client:0.7.1-patch1\"\n",
    "    # ,\"com.clickhouse:clickhouse-http-client:0.6.0-patch5\"\n",
    "    ,\"org.apache.httpcomponents.client5:httpclient5:5.3.1\"\n",
    "    # for jdbc 2.7.1 required java 8/11\n",
    "    # ,\"com.github.housepower:clickhouse-native-jdbc:2.7.1\"\n",
    "    ,\"ai.catboost:catboost-spark_3.5_2.12:1.2.7\"\n",
    "    ,\"com.microsoft.azure:synapseml_2.12:1.0.8\"\n",
    "\n",
    "]\n",
    "\n",
    "exclude_packages = [\n",
    "    \"org.scala-lang:scala-reflect\"\n",
    "    ,\"org.apache.spark:spark-tags_2.12\"\n",
    "    ,\"org.scalactic:scalactic_2.12\"\n",
    "    ,\"org.scalatest:scalatest_2.12\"\n",
    "    ,\"com.fasterxml.jackson.core:jackson-databind\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ram = 60\n",
    "cpu = 22*3\n",
    "# Define the application name and setup session\n",
    "appName = \"Connect To ClickHouse via PySpark\"\n",
    "spark = (SparkSession.builder\n",
    "         .appName(appName)\n",
    "         .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "         .config(\"spark.sql.catalog.clickhouse\", \"com.clickhouse.spark.ClickHouseCatalog\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.host\", CH_IP)\n",
    "         .config(\"spark.sql.catalog.clickhouse.protocol\", \"http\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.http_port\", \"8123\")\n",
    "         .config(\"spark.sql.catalog.clickhouse.user\", CH_USER)\n",
    "         .config(\"spark.sql.catalog.clickhouse.password\", CH_PASS)\n",
    "         .config(\"spark.sql.catalog.clickhouse.database\", \"default\")\n",
    "        #  .config(\"spark.spark.clickhouse.write.compression.codec\", \"lz4\")\n",
    "        #  .config(\"spark.clickhouse.read.compression.codec\", \"lz4\")\n",
    "        #  .config(\"spark.clickhouse.write.format\", \"arrow\")\n",
    "         #    .config(\"spark.clickhouse.write.distributed.convertLocal\", \"true\") l\n",
    "         #    .config(\"spark.clickhouse.write.repartitionNum\", \"1\") \n",
    "         #.config(\"spark.clickhouse.write.maxRetry\", \"1000\")\n",
    "         #    .config(\"spark.clickhouse.write.repartitionStrictly\", \"true\") \n",
    "         #    .config(\"spark.clickhouse.write.distributed.useClusterNodes\", \"false\") \n",
    "        #  .config(\"spark.clickhouse.write.batchSize\", \"1000000\")\n",
    "         #.config(\"spark.sql.catalog.clickhouse.socket_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.sql.catalog.clickhouse.connection_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.sql.catalog.clickhouse.query_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.socket_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.connection_timeout\", \"600000000\")\n",
    "        #  .config(\"spark.clickhouse.options.query_timeout\", \"600000000\")         \n",
    "         .config(\"spark.executor.memory\", f\"{ram}g\")\n",
    "        #  .config(\"spark.executor.cores\", \"5\")\n",
    "         .config(\"spark.driver.maxResultSize\", f\"{ram}g\")\n",
    "         .config(\"spark.driver.memory\", f\"{ram}g\")\n",
    "         .config(\"spark.executor.memoryOverhead\", f\"{ram}g\")\n",
    "        #  .config(\"spark.sql.debug.maxToStringFields\", \"100000\")\n",
    "         .getOrCreate()\n",
    "         )\n",
    "\n",
    "# LightGBM set config https://microsoft.github.io/SynapseML/docs/Get%20Started/Install%20SynapseML/\n",
    "# spark.conf.set(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "# spark.conf.set(\"spark.jars.excludes\", \",\".join(exclude_packages))\n",
    "# spark.conf.set(\"spark.yarn.user.classpath.first\", \"true\")\n",
    "# spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "\n",
    "#SedonaRegistrator.registerAll(spark)\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse\", \"xenon.clickhouse.ClickHouseCatalog\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.host\", \"127.0.0.1\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.protocol\", \"http\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.http_port\", \"8123\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.user\", \"default\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.password\", \"\")\n",
    "# spark.conf.set(\"spark.sql.catalog.clickhouse.database\", \"default\")\n",
    "\n",
    "\n",
    "\n",
    "from catboost_spark import CatBoostRegressor as CatBoostRegressor_spark\n",
    "from synapse.ml.lightgbm import LightGBMRegressor as LightGBMRegressor_spark\n",
    "\n",
    "\n",
    "spark.sql(\"use clickhouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server-Side: FastAPI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "class DataFrameInput(BaseModel):\n",
    "    data: List[Dict]  # Expecting a list of dictionaries as input\n",
    "\n",
    "@app.post(\"/process-dataframe\")\n",
    "async def process_dataframe(input_data: DataFrameInput):\n",
    "    # Convert the JSON data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(input_data.data)\n",
    "    \n",
    "    # Modify the DataFrame (example: add a new column)\n",
    "    df[\"new_column\"] = df[\"column1\"] * 2  # Assuming 'column1' exists in the input\n",
    "    \n",
    "    # Convert the modified DataFrame back to JSON\n",
    "    response_data = df.to_dict(orient=\"records\")\n",
    "    return {\"data\": response_data}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/control\")\n",
    "async def get_control(id: int):\n",
    "    control = client.query_df(f'''\n",
    "        select * \n",
    "        from ycup.control yc\n",
    "        where yc.id = {id}\n",
    "        limit 10'''\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clickhouse connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>localization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>metadata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name\n",
       "0       control\n",
       "1  localization\n",
       "2      metadata"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_df('SHOW TABLES IN ycup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_cols_for_model(test: pd.DataFrame, target: str=None, targets: list=None) -> list:\n",
    "    '''Set num and cat columns for model'''\n",
    "    \n",
    "    cols_checked = test.columns\n",
    "\n",
    "    # target in [ ] because yaw hase more then one letter\n",
    "    not_target = list(set(targets) - set([target]))\n",
    "\n",
    "\n",
    "    # Set num columns\n",
    "    control_cols = ['ctrl_stamp_ns', 'acceleration_level', 'steering']\n",
    "    shift_cols = [col for col in cols_checked if '_shift' in col]\n",
    "    tmp = [col for col in shift_cols for nt in not_target if f'{nt}_' in col]\n",
    "    shift_cols = list(set(shift_cols) - set(tmp))\n",
    "\n",
    "    last_10_cols = [col for col in cols_checked if 'last_10' in col]\n",
    "    tmp = [col for col in last_10_cols for nt in not_target if f'{nt}_' in col]\n",
    "    last_10_cols = list(set(last_10_cols) - set(tmp))\n",
    "\n",
    "    num_cols = control_cols + shift_cols + last_10_cols\n",
    "\n",
    "    # Set categorical columns\n",
    "    cols_temp = [col for col in cols_checked if col in control_cols or 'last' in col or 'shift' in col or 'diff' in col]\n",
    "    cat_cols = list(set(cols_checked) - set(cols_temp) - set(targets))\n",
    "\n",
    "\n",
    "    return cat_cols, num_cols\n",
    "\n",
    "\n",
    "\n",
    "# catboost encoder\n",
    "def ctb_encoder(test: pd.DataFrame, target: str, id: int, targets: list) -> pd.DataFrame:\n",
    "    '''Encode with CatBoostEncoder categorical columns of each target test data    '''     \n",
    "    # drop unnecessary columns\n",
    "    test_target = test[test['id'] == id].drop(columns=['z', 'roll', 'pitch'])\n",
    "\n",
    "    # set columns for one target\n",
    "    cat_cols, num_cols = set_cols_for_model(test_target, target, targets)\n",
    "\n",
    "    # obsereved columns\n",
    "    obs_cols = [col for col in test_target.columns if 'obs' in col] \n",
    "\n",
    "    \n",
    "    # use only columns for one target and 'shift_1_obs' doesn't need to encode\n",
    "    test_target = test_target.loc[:, cat_cols + list(set(num_cols) - set(obs_cols))]\n",
    "\n",
    "    # fill null in target_shift column for correct work CatBoostEncoder\n",
    "    test_target.fillna(value={f'{target}_shift_1': -1}, inplace=True)\n",
    "\n",
    "    # encode categorical columns\n",
    "    test_target = ce.CatBoostEncoder(cols=cat_cols).fit_transform(test_target, test_target[f'{target}_shift_1'])\n",
    "\n",
    "    # del num and reminder from col names\n",
    "    # train_target.columns = [col.split(\"__\")[1] if \"__\" in col else col for col in train_target.columns]\n",
    "\n",
    "    # replace -1 to nan\n",
    "    test_target[f'{target}_shift_1'].replace(-1, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "    # add target column to the end\n",
    "    test_target[target] = test[target]\n",
    " \n",
    "    test_target['id_obs'] = id\n",
    "\n",
    "    \n",
    "    return test_target\n",
    "\n",
    "\n",
    "def df_preprocessor(test: pd.DataFrame, target: str, id: int, preprocessor_path: str, targets: list) -> pd.DataFrame:\n",
    "    '''Preprocess test one id_obs data for model\n",
    "    cat_cols encoded with CatBoostEncoder\n",
    "    num_cols transformed with PowerTransformer\n",
    "   \n",
    "    test - copy of test data\n",
    "    '''\n",
    "    \n",
    "    test_id = test[test['id'] == id]\n",
    "\n",
    "    # add target columns with shifts\n",
    "    for i in range(1, 4):\n",
    "        test_id[f'{target}_shift_{i}'] = test_id[target].shift(i)\n",
    "\n",
    "    # add mean last 10 values for target columns\n",
    "    test_id[f'{target}_last_10_mean'] = test_id[target].rolling(window=10).mean()\n",
    "\n",
    "    # # add obs shift_1 column to preprocessed data\n",
    "    # test_id[f'{target}_shift_1_obs'] = test_id[f'{target}_shift_1']\n",
    "\n",
    "    # load preprocessor\n",
    "    # cat_encoder = pd.read_pickle(f'{tmp_data_path}/cat_encoder_{target}.pkl')\n",
    "    preprocessor = pd.read_pickle(f'{preprocessor_path}/preprocessor_{target}.pkl')\n",
    "    \n",
    "    # transform the encoded test data with preprocessor\n",
    "    test_prepr = preprocessor.transform(ctb_encoder(test_id, target, id, targets))\n",
    "\n",
    "    # del num and reminder from col names\n",
    "    test_prepr.columns = [col.split(\"__\")[1] if \"__\" in col else col for col in test_prepr.columns]\n",
    "    \n",
    "    # add diff target columns to preprocessed data\n",
    "    test_id[f'{target}_diff'] = test_id[target] - test_id[f'{target}_shift_1']\n",
    "    test_id.fillna(value={f'{target}_diff':0}, inplace=True)\n",
    "    test_prepr[f'{target}_diff'] = test_id[f'{target}_diff']\n",
    "\n",
    "    # add 'shift_1_obs' column to preprocessed data\n",
    "    test_prepr[f'{target}_shift_1_obs'] = test_id[f'{target}_shift_1']\n",
    "\n",
    "    # replace null values with -100 for correct work of VectorAssembler. -100 is out of range after preprocessing by PowerTransformer\n",
    "    test_prepr = test_prepr.fillna(-100)\n",
    "\n",
    "    # add target columns to preprocessed data\n",
    "    test_prepr[f'{target}'] = test_id[target]\n",
    "\n",
    "    # add row_number_by_id column\n",
    "    test_prepr['row_number_by_id'] = test_prepr.sort_values(['id_obs', 'ctrl_stamp_ns']).groupby('id_obs').cumcount()\n",
    "\n",
    "\n",
    "    return test_prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_control', 'test_localization', 'test_metadata']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[table for table in client.query_df('show tables from ycup')['name'].values if 'test' in table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(client, table_name: str, id: int) -> pd.DataFrame:\n",
    "    '''Get df from clickhouse by table name and id'''\n",
    "    df = client.query_df(f'''select * from ycup.{table_name} where id = {id}''')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctrl_stamp_ns</th>\n",
       "      <th>acceleration_level</th>\n",
       "      <th>steering</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>y_shift_2</th>\n",
       "      <th>y_shift_3</th>\n",
       "      <th>yaw_shift_1</th>\n",
       "      <th>yaw_shift_2</th>\n",
       "      <th>yaw_shift_3</th>\n",
       "      <th>acceleration_level_last_10_mean</th>\n",
       "      <th>steering_last_10_mean</th>\n",
       "      <th>x_last_10_mean</th>\n",
       "      <th>y_last_10_mean</th>\n",
       "      <th>yaw_last_10_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36479492</td>\n",
       "      <td>-929</td>\n",
       "      <td>5.739836</td>\n",
       "      <td>-1482.652694</td>\n",
       "      <td>-1321.883413</td>\n",
       "      <td>-16.014849</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>2.240336</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76459951</td>\n",
       "      <td>-926</td>\n",
       "      <td>5.280618</td>\n",
       "      <td>-1482.766079</td>\n",
       "      <td>-1321.739951</td>\n",
       "      <td>-16.013857</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>-0.001575</td>\n",
       "      <td>2.241208</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.240336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116678417</td>\n",
       "      <td>-918</td>\n",
       "      <td>5.039505</td>\n",
       "      <td>-1482.878241</td>\n",
       "      <td>-1321.598810</td>\n",
       "      <td>-16.010625</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>-0.001459</td>\n",
       "      <td>2.242182</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1321.883413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.241208</td>\n",
       "      <td>2.240336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156788958</td>\n",
       "      <td>-908</td>\n",
       "      <td>4.734873</td>\n",
       "      <td>-1482.990065</td>\n",
       "      <td>-1321.458237</td>\n",
       "      <td>-16.010063</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>2.243131</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1321.739951</td>\n",
       "      <td>-1321.883413</td>\n",
       "      <td>2.242182</td>\n",
       "      <td>2.241208</td>\n",
       "      <td>2.240336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196857808</td>\n",
       "      <td>-897</td>\n",
       "      <td>4.387096</td>\n",
       "      <td>-1483.100891</td>\n",
       "      <td>-1321.319065</td>\n",
       "      <td>-16.009805</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>2.244002</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1321.598810</td>\n",
       "      <td>-1321.739951</td>\n",
       "      <td>2.243131</td>\n",
       "      <td>2.242182</td>\n",
       "      <td>2.241208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>19837060299</td>\n",
       "      <td>5889</td>\n",
       "      <td>-3.057310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6142.8</td>\n",
       "      <td>-2.844868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>19877059284</td>\n",
       "      <td>5087</td>\n",
       "      <td>-3.112980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6042.6</td>\n",
       "      <td>-2.886396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>19917145118</td>\n",
       "      <td>4193</td>\n",
       "      <td>-3.112980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5847.2</td>\n",
       "      <td>-2.927923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>19957108547</td>\n",
       "      <td>3414</td>\n",
       "      <td>-3.183301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5571.4</td>\n",
       "      <td>-2.976483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>19997177777</td>\n",
       "      <td>2782</td>\n",
       "      <td>-3.237437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5229.3</td>\n",
       "      <td>-3.025078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ctrl_stamp_ns  acceleration_level  steering            x            y  \\\n",
       "0         36479492                -929  5.739836 -1482.652694 -1321.883413   \n",
       "1         76459951                -926  5.280618 -1482.766079 -1321.739951   \n",
       "2        116678417                -918  5.039505 -1482.878241 -1321.598810   \n",
       "3        156788958                -908  4.734873 -1482.990065 -1321.458237   \n",
       "4        196857808                -897  4.387096 -1483.100891 -1321.319065   \n",
       "..             ...                 ...       ...          ...          ...   \n",
       "495    19837060299                5889 -3.057310          NaN          NaN   \n",
       "496    19877059284                5087 -3.112980          NaN          NaN   \n",
       "497    19917145118                4193 -3.112980          NaN          NaN   \n",
       "498    19957108547                3414 -3.183301          NaN          NaN   \n",
       "499    19997177777                2782 -3.237437          NaN          NaN   \n",
       "\n",
       "             z      roll     pitch       yaw  id  ...    y_shift_2  \\\n",
       "0   -16.014849  0.027502 -0.001965  2.240336   0  ...          NaN   \n",
       "1   -16.013857  0.027058 -0.001575  2.241208   0  ...          NaN   \n",
       "2   -16.010625  0.027793 -0.001459  2.242182   0  ... -1321.883413   \n",
       "3   -16.010063  0.027618 -0.001372  2.243131   0  ... -1321.739951   \n",
       "4   -16.009805  0.028147 -0.001524  2.244002   0  ... -1321.598810   \n",
       "..         ...       ...       ...       ...  ..  ...          ...   \n",
       "495        NaN       NaN       NaN       NaN   0  ...          NaN   \n",
       "496        NaN       NaN       NaN       NaN   0  ...          NaN   \n",
       "497        NaN       NaN       NaN       NaN   0  ...          NaN   \n",
       "498        NaN       NaN       NaN       NaN   0  ...          NaN   \n",
       "499        NaN       NaN       NaN       NaN   0  ...          NaN   \n",
       "\n",
       "       y_shift_3  yaw_shift_1  yaw_shift_2  yaw_shift_3  \\\n",
       "0            NaN          NaN          NaN          NaN   \n",
       "1            NaN     2.240336          NaN          NaN   \n",
       "2            NaN     2.241208     2.240336          NaN   \n",
       "3   -1321.883413     2.242182     2.241208     2.240336   \n",
       "4   -1321.739951     2.243131     2.242182     2.241208   \n",
       "..           ...          ...          ...          ...   \n",
       "495          NaN          NaN          NaN          NaN   \n",
       "496          NaN          NaN          NaN          NaN   \n",
       "497          NaN          NaN          NaN          NaN   \n",
       "498          NaN          NaN          NaN          NaN   \n",
       "499          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     acceleration_level_last_10_mean  steering_last_10_mean  x_last_10_mean  \\\n",
       "0                                NaN                    NaN             NaN   \n",
       "1                                NaN                    NaN             NaN   \n",
       "2                                NaN                    NaN             NaN   \n",
       "3                                NaN                    NaN             NaN   \n",
       "4                                NaN                    NaN             NaN   \n",
       "..                               ...                    ...             ...   \n",
       "495                           6142.8              -2.844868             NaN   \n",
       "496                           6042.6              -2.886396             NaN   \n",
       "497                           5847.2              -2.927923             NaN   \n",
       "498                           5571.4              -2.976483             NaN   \n",
       "499                           5229.3              -3.025078             NaN   \n",
       "\n",
       "     y_last_10_mean  yaw_last_10_mean  \n",
       "0               NaN               NaN  \n",
       "1               NaN               NaN  \n",
       "2               NaN               NaN  \n",
       "3               NaN               NaN  \n",
       "4               NaN               NaN  \n",
       "..              ...               ...  \n",
       "495             NaN               NaN  \n",
       "496             NaN               NaN  \n",
       "497             NaN               NaN  \n",
       "498             NaN               NaN  \n",
       "499             NaN               NaN  \n",
       "\n",
       "[500 rows x 39 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [0]\n",
    "targets = ['x']\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id in ids:\n",
    "    test_control = get_df(client, 'test_control', id)\n",
    "    test_localizations = get_df(client, 'test_localization', id)\n",
    "    test_metadata = get_df(client, 'test_metadata', id)   \n",
    "    df_list.append(union_dfs(test_control, test_localizations, test_metadata))\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['x', 'y', 'yaw', 'z', 'roll', 'pitch']\n",
    "target = 'x'\n",
    "\n",
    "cols_checked = df.columns\n",
    "\n",
    "# target in [ ] because yaw hase more then one letter\n",
    "not_target = list(set(targets) - set([target]))\n",
    "\n",
    "\n",
    "# Set num columns\n",
    "control_cols = ['ctrl_stamp_ns', 'acceleration_level', 'steering']\n",
    "shift_cols = [col for col in cols_checked if '_shift' in col]\n",
    "tmp = [col for col in shift_cols for nt in not_target if f'{nt}_' in col]\n",
    "shift_cols = list(set(shift_cols) - set(tmp))\n",
    "\n",
    "last_10_cols = [col for col in cols_checked if 'last_10' in col]\n",
    "tmp = [col for col in last_10_cols for nt in not_target if f'{nt}_' in col]\n",
    "last_10_cols = list(set(last_10_cols) - set(tmp))\n",
    "\n",
    "num_cols = control_cols + shift_cols + last_10_cols\n",
    "\n",
    "# Set categorical columns\n",
    "cols_temp = [col for col in cols_checked if col in control_cols or 'last' in col or 'shift' in col or 'diff' in col]\n",
    "cat_cols = list(set(cols_checked) - set(cols_temp) - set(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['vehicle_model_modification',\n",
       "  'rear_tire',\n",
       "  'location_reference_point_id',\n",
       "  'vehicle_model',\n",
       "  'id',\n",
       "  'front_tire',\n",
       "  'ride_month',\n",
       "  'ride_year',\n",
       "  'ride_day',\n",
       "  'vehicle_id'],\n",
       " ['ctrl_stamp_ns',\n",
       "  'acceleration_level',\n",
       "  'steering',\n",
       "  'acceleration_level_shift_3',\n",
       "  'steering_shift_2',\n",
       "  'x_shift_2',\n",
       "  'steering_shift_3',\n",
       "  'x_shift_3',\n",
       "  'acceleration_level_shift_2',\n",
       "  'x_shift_1',\n",
       "  'acceleration_level_shift_1',\n",
       "  'steering_shift_1',\n",
       "  'steering_last_10_mean',\n",
       "  'x_last_10_mean',\n",
       "  'acceleration_level_last_10_mean'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = ['x', 'y', 'yaw', 'z', 'roll', 'pitch']\n",
    "target = 'x'\n",
    "set_cols_for_model(df, target, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df_prepr \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[0;32m----> 5\u001b[0m     df_prepr[target] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_preprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 94\u001b[0m, in \u001b[0;36mdf_preprocessor\u001b[0;34m(test, target, id, preprocessor_path, targets)\u001b[0m\n\u001b[1;32m     91\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreprocessor_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/preprocessor_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# transform the encoded test data with preprocessor\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m test_prepr \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mctb_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# del num and reminder from col names\u001b[39;00m\n\u001b[1;32m     97\u001b[0m test_prepr\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;28;01melse\u001b[39;00m col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m test_prepr\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "Cell \u001b[0;32mIn[26], line 51\u001b[0m, in \u001b[0;36mctb_encoder\u001b[0;34m(test, target, id, targets)\u001b[0m\n\u001b[1;32m     48\u001b[0m test_target\u001b[38;5;241m.\u001b[39mfillna(value\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shift_1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# encode categorical columns\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m test_target \u001b[38;5;241m=\u001b[39m \u001b[43mce\u001b[49m\u001b[38;5;241m.\u001b[39mCatBoostEncoder(cols\u001b[38;5;241m=\u001b[39mcat_cols)\u001b[38;5;241m.\u001b[39mfit_transform(test_target, test_target[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shift_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# del num and reminder from col names\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# train_target.columns = [col.split(\"__\")[1] if \"__\" in col else col for col in train_target.columns]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# replace -1 to nan\u001b[39;00m\n\u001b[1;32m     57\u001b[0m test_target[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shift_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ce' is not defined"
     ]
    }
   ],
   "source": [
    "targets = ['x', 'y', 'yaw', 'z', 'roll', 'pitch']\n",
    "\n",
    "df_prepr = {}\n",
    "for target in targets:\n",
    "    df_prepr[target] = df_preprocessor(df, target, id, preprocessor_path, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'ycup'\n",
    "# list of tables in db\n",
    "tables = spark.sql(f'SHOW TABLES in {db}').collect()\n",
    "\n",
    "df_list = {}\n",
    "for table in tables:\n",
    "    table_name = table.tableName\n",
    "    df = spark.sql(f'SELECT * FROM {db}.{table_name} limit 10').toPandas()\n",
    "    df_list[table_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second variant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stamp_ns</th>\n",
       "      <th>acceleration_level</th>\n",
       "      <th>steering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36479492</td>\n",
       "      <td>-929</td>\n",
       "      <td>5.739836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>76459951</td>\n",
       "      <td>-926</td>\n",
       "      <td>5.280618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>116678417</td>\n",
       "      <td>-918</td>\n",
       "      <td>5.039505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>156788958</td>\n",
       "      <td>-908</td>\n",
       "      <td>4.734873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>196857808</td>\n",
       "      <td>-897</td>\n",
       "      <td>4.387096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>236974997</td>\n",
       "      <td>-892</td>\n",
       "      <td>4.014573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>276890721</td>\n",
       "      <td>-892</td>\n",
       "      <td>3.627408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>316915752</td>\n",
       "      <td>-901</td>\n",
       "      <td>3.191926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>356884436</td>\n",
       "      <td>-911</td>\n",
       "      <td>2.748362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>396895329</td>\n",
       "      <td>-918</td>\n",
       "      <td>2.286391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   stamp_ns  acceleration_level  steering\n",
       "0   0   36479492                -929  5.739836\n",
       "1   0   76459951                -926  5.280618\n",
       "2   0  116678417                -918  5.039505\n",
       "3   0  156788958                -908  4.734873\n",
       "4   0  196857808                -897  4.387096\n",
       "5   0  236974997                -892  4.014573\n",
       "6   0  276890721                -892  3.627408\n",
       "7   0  316915752                -901  3.191926\n",
       "8   0  356884436                -911  2.748362\n",
       "9   0  396895329                -918  2.286391"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client-Side: Sending and Receiving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running the Server\n",
    "\n",
    "\n",
    "```\n",
    "uvicorn your_script_name:app --reload\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
