{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Предсказание движения беспилотного автомобиля\n",
    "\n",
    "Когда в XIX веке на улицах Великобритании появились первые самоходные повозки, они вызвали у людей скорее страх и недоверие, чем восторг. Поэтому в 1865 году в Великобритании был принят The Locomotive Act, более известный как Red Flag Act, который требовал, чтобы перед каждым автомобилем шёл человек с красным флажком или фонарём. Этот «предвестник прогресса» должен был предупреждать пешеходов и конные экипажи о приближении нового механического транспорта.\n",
    "\n",
    "Кроме того, закон строго ограничивал скорость автомобилей: не более 2 миль в час в городах и 4 миль в час за их пределами. Эти меры были направлены на то, чтобы адаптировать общество к новым транспортным средствам и минимизировать их риски для безопасности. К концу XIX века стало очевидно, что подобные ограничения только сдерживают прогресс, и в 1896 году Red Flag Act был отменён, а автомобили получили право двигаться быстрее и без «предвестника», предсказывающего появление автомобиля.\n",
    "\n",
    "Сегодня предсказание маршрута автомобиля стало делом не человека с флажком, а искусственного интеллекта. ИИ способен опираться на огромное количество данных — от состояния дорог и трафика до погодных условий и угла поворота колёс — чтобы не просто направить автомобиль, а выбрать для него наилучший маршрут.\n",
    "\n",
    "Ваша задача — обучить модель, позволяющую точно моделировать траекторию движения автомобиля на основе поступающих команд управления, технических характеристик и исторических данных о прошлых проездах транспорта по различным дорогам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные для обучения\n",
    "Архив YaCupTrain.tar содержит набор из N train записанных сцен проезда легкового автомобиля, разложенных по отдельным папкам. Каждая папка содержит 3 файла:\n",
    "\n",
    "metadata.json: содержит общую информацию про сцену\n",
    "ride_date — дата проезда\n",
    "vehicle_id — уникальный идентификатор автомобиля\n",
    "vehicle_model — идентификатор модели автомобиля\n",
    "vehicle_model_modification — идентификатор модификации указанной модели автомобиля\n",
    "tires — идентификатор типа шин, используемых для колёс передней (front) и задней (rear) оси автомобиля\n",
    "location_reference_point_id — идентификатор референсной точки, используемой в качестве начала отсчёта координат в файле localization.csv\n",
    "localization.csv: описывает траекторию движения автомобиля на данной 60-секундной сцене. Представляет собой csv файл, каждая строчка которого имеет формат\n",
    "stamp_ns — время в наносекундах от начала сцены\n",
    "x, y, z — координаты центра задней оси автомобиля. Считаются в метрах от указанной референсной точки сцены. Направления осей относительно референсной точки: \n",
    "x - на восток, \n",
    "y - на север, \n",
    "z - в небо\n",
    "roll, pitch, yaw — углы Эйлера в радианах, описывающие ориентацию автомобиля в пространстве. Угол yaw считается относительно оси \n",
    "x в направлении оси y.\n",
    "control.csv: описывает последовательность команд управления, отправленных автомобилю на протяжении данной сцены.\n",
    "stamp_ns — время в наносекундах от начала сцены\n",
    "acceleration_level — желаемая интенсивность ускорения. Положительные значения соответствуют силе нажатия на педаль газа, отрицательные — силе нажатия на педаль тормоза\n",
    "steering — желаемый угол поворота руля в градусах относительно центрального положения\n",
    "Обратите внимание, что диапазон значений acceleration_level зависит от модели автомобиля. Также, важно отметить, что данные команды описывают желаемое целевое состояние элементов управления в указанный момент времени, и не обязательно исполняются мгновенно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные для тестирования\n",
    "Архив YaCupTest.tar содержит набор из N test    сцен, для которых требуется предсказать новую траекторию автомобиля на основе начального состояния и поступающих команд управления. Каждая папка с тестовым сценарием содержит 4 файла:\n",
    "\n",
    "metadata.json: содержит общую информацию про сцену аналогично обучающим данным\n",
    "localization.csv: описывает траекторию движения автомобиля в течении первых 5 секунд сцены. Формат аналогичен обучающим данным.\n",
    "control.csv: описывает последовательность команд управления в течении первых 20 секунд сцены. Формат аналогичен обучающим данным.\n",
    "requested_stamps.csv: содержит одну колонку stamp_ns, содержающую список из \n",
    "T n  моментов времени от начала сцены (в наносекундах) в интервале с 5 по 20 секунду, для которых требуется предсказать положение автомобиля.\n",
    "\n",
    "## Формат вывода\n",
    "В качестве решения вам необходимо отправить один файл в формате *.csv, содержащий следующие 5 колонок:\n",
    "\n",
    "testcase_id — номер сцены из тестового набора (имя папки от 0 до N test −1)\n",
    "stamp_ns — моменты времени из соответствующего файла requested_stamps.csv тестовой сцены.\n",
    "x, y, yaw — 3 колонки с предсказанными координатами положения машины и её ориентации на плоскости в указанные моменты времени (В формате аналогичном входным данным).\n",
    "Таким образом, общее количество строк с предсказаниями в файле с ответом должно совпадать с суммарным количеством таймстемпов в файлах requested_stamps.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe final metric. As a first step, all predicted triples $(x,y,yaw)$ are being converted into 2 points $[(x_1, y_1), (x_2, y_2)]$ in the following way:\n",
    "$$\n",
    "(x_1, y_1) = (x, y), \\\\\n",
    "(x_2, y_2) = (x_1, y_1) + S \\times (yaw_x, yaw_y)\n",
    "$$  \n",
    "\n",
    "where $S = 1$. In other words, we build a directed segment of length $1$. These points then used in the metric calculation.\n",
    "\n",
    "\n",
    "Metric for a single pose (rmse):\n",
    "\n",
    "$$\n",
    "pose\\_metric = \\sqrt{ \\frac{\\displaystyle\\sum_{j=1}^{k} {(x_j-\\hat{x_j})^2 + (y_j-\\hat{y_j})^2}}{k} }\n",
    "$$\n",
    "\n",
    "where $k$ - number of points that describe single pose (in our case $k=2$).\n",
    "\n",
    "Metric for a testcase:\n",
    "\n",
    "$$\n",
    "testcase\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}pose\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of localization points to predict.\n",
    "\n",
    "And, final metric for a whole dataset:\n",
    "\n",
    "$$\n",
    "dataset\\_metric = \\frac{1}{n}  \\displaystyle\\sum_{i=1}^{n}testcase\\_metric_i\n",
    "$$\n",
    "\n",
    "where $n$ - number of test cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import clickhouse_connect\n",
    "import os\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# constants\n",
    "CH_USER = os.getenv(\"CH_USER\")\n",
    "CH_PASS = os.getenv(\"CH_PASS\")\n",
    "CH_IP = os.getenv('CH_IP')\n",
    "\n",
    "# from tools import create_db_table_from_df, pd_tools, spark_tools\n",
    "\n",
    "root_path = \".\"\n",
    "tmp_path = f'{root_path}/tmp'\n",
    "data_path = f'{root_path}/data'\n",
    "data_test_path = f'{data_path}/test_data'\n",
    "data_train_path = f'{data_path}/train_data'\n",
    "prod_data_path = f'{data_path}/prod_data'\n",
    "new_data_path=f'{data_path}/new_data'\n",
    "tmp_data_path=f'{data_path}/tmp_data'\n",
    "\n",
    "ch_client = clickhouse_connect.get_client(host=CH_IP, port=8123, username=CH_USER, password=CH_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cargo.csv',\n",
       " 'leg.csv',\n",
       " 'leg_result.csv',\n",
       " 'leg_result_202407202150.csv',\n",
       " 'leg_service.csv',\n",
       " 'new_data',\n",
       " 'point_to_point_distance.csv',\n",
       " 'point_to_point_distance_202405132042.csv',\n",
       " 'point_to_point_duration_202405171813.csv',\n",
       " 'price_attributes.csv',\n",
       " 'prod_data',\n",
       " 'p_bet_nds.csv',\n",
       " 'p_coefficient.csv',\n",
       " 'p_margin.csv',\n",
       " 'p_price.csv',\n",
       " 'p_price_converted.csv',\n",
       " 'p_price_expenditure.csv',\n",
       " 'p_route_edge.csv',\n",
       " 'p_route_vertex.csv',\n",
       " 'result.csv',\n",
       " 'result_2_1.csv',\n",
       " 'result__202404291303.csv',\n",
       " 'result__202405072301.csv',\n",
       " 'route_service.csv',\n",
       " 's_common.csv',\n",
       " 's_complex_service.csv',\n",
       " 's_country.csv',\n",
       " 's_currency.csv',\n",
       " 's_freight_etsng.csv',\n",
       " 's_freight_etsng_dan.csv',\n",
       " 's_freight_gng.csv',\n",
       " 's_point.csv',\n",
       " 's_point_202405132050.csv',\n",
       " 's_point_202405141449.csv',\n",
       " 's_point_geo',\n",
       " 's_point_geo.csv',\n",
       " 's_point_geo_temp.csv',\n",
       " 's_point_temp.csv',\n",
       " 's_point_type.csv',\n",
       " 's_ref_type_application.csv',\n",
       " 's_service.csv',\n",
       " 's_stage_transportation.csv',\n",
       " 's_type_application.csv',\n",
       " 's_unit_measurement.csv',\n",
       " 'tmp_data',\n",
       " 'transport_solution.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Read folder names or file names in the path'''\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mread_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mread_names\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_names\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Read folder names or file names in the path'''\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train_data'"
     ]
    }
   ],
   "source": [
    "# read folder names in data path\n",
    "def read_names(path: str):\n",
    "    '''Read folder names or file names in the path'''\n",
    "    return os.listdir(path)\n",
    "\n",
    "read_names(data_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train_data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(case_id) \u001b[38;5;28;01mfor\u001b[39;00m case_id \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dataset_path) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, case_id))]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ids\n\u001b[0;32m----> 7\u001b[0m train_ids \u001b[38;5;241m=\u001b[39m \u001b[43mread_testcase_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m test_ids \u001b[38;5;241m=\u001b[39m read_testcase_ids(data_test_path)\n\u001b[1;32m     10\u001b[0m train_ids\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mread_testcase_ids\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_testcase_ids\u001b[39m(dataset_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(case_id) \u001b[38;5;28;01mfor\u001b[39;00m case_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, case_id))]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train_data'"
     ]
    }
   ],
   "source": [
    "# Load all ids of a dataset\n",
    "\n",
    "def read_testcase_ids(dataset_path: str):\n",
    "    ids = [int(case_id) for case_id in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, case_id))]\n",
    "    return ids\n",
    "\n",
    "train_ids = read_testcase_ids(data_train_path)\n",
    "test_ids = read_testcase_ids(data_test_path)\n",
    "\n",
    "train_ids.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
