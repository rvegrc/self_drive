{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window function \n",
    "\n",
    "# first way sql\n",
    "# test_x.createOrReplaceTempView('test_x')\n",
    "# test_x = spark.sql('''\n",
    "#     SELECT\n",
    "#         *\n",
    "#         ,row_number() over (partition by id order by ctrl_stamp_ns) as row_number\n",
    "#     from test_x\n",
    "# ''')\n",
    "\n",
    "# second way\n",
    "\n",
    "# window_spec = Window.partitionBy('id').orderBy('ctrl_stamp_ns')\n",
    "\n",
    "# # divide test data to partitions by id\n",
    "# test_x = test_x.withColumn('row_number', F.row_number().over(window_spec))\n",
    "\n",
    "\n",
    "# test_x.show()\n",
    "\n",
    "\n",
    "\n",
    "# def shift_last_10_mean(test_prepr:SparkDataFrame):\n",
    "#   '''Shift and add mean last 10 values for test_prepr'''\n",
    "#   # Define the window specification\n",
    "#   window_spec = Window.partitionBy(\"id_obs\").orderBy(\"row_number_by_id\")\n",
    "\n",
    "#   # Apply lag function\n",
    "#   for n in range(1, 11):\n",
    "#     test_prepr = test_prepr.withColumn(f\"{target}_shift_{n}\", F.lag(target, n, -100).over(window_spec))\n",
    "\n",
    "#   # Apply mean last 10 values\n",
    "#   test_prepr = test_prepr.withColumn(f'{target}_last_10_mean', F.mean(f'{target}').over(window_spec.rangeBetween(-10, -1)))\n",
    "\n",
    "#   # drop unnecessary columns\n",
    "#   test_prepr = test_prepr.drop(f'{target}_shift_4', f'{target}_shift_5', f'{target}_shift_6', f'{target}_shift_7', f'{target}_shift_8'\n",
    "#                                              , f'{target}_shift_9', f'{target}_shift_10')\n",
    "# return test_prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_spec = Window.partitionBy('id').orderBy('ctrl_stamp_ns')\n",
    "\n",
    "# # divide test data to partitions by id\n",
    "# test_x = test_x.withColumn('row_number', F.row_number().over(window_spec))\n",
    "# test_x.show(127)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the window specification\n",
    "# window_spec = Window.partitionBy(\"id_obs\").orderBy(\"row_number_by_id\")\n",
    "\n",
    "# # Apply lag function\n",
    "# test_prepr.withColumn(\n",
    "#     f\"{target}_shift_1\", F.lag(f\"{target}\", 1, -100).over(window_spec)\n",
    "# ).show()\n",
    "\n",
    "# test_prepr.createOrReplaceTempView('predictions')\n",
    "# spark_tools.check_nn_spark(spark.sql('''\n",
    "#           select\n",
    "#             lag(x, 1, 0) over (partition by id_obs order by row_number_by_id) as x_shift_1\n",
    "#           from predictions\n",
    "#         ''')\n",
    "# )\n",
    "\n",
    "# test_prepr.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
